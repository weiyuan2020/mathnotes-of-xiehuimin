% chap08sec02
\section{The exponential and logarithmic functions}
We define
\begin{equation}
    \label{eq:8.25}
    E(z) = 
    \sum_{n=0}^{\infty} \frac{z^n}{n!}
\end{equation}

The ratio test shows that this series converges for every complex $z$. Applying Theorem \ref{thm:3.50} on multiplication of absolutely convergent series, we obtain
\begin{align*}
    E(z) E(w) 
    &= \sum_{n=0}^{\infty} \frac{z^n}{n!} \sum_{m=0}^{\infty} \frac{w^m}{m!}
    = \sum_{n=0}^{\infty} \sum_{k=0}^{n} \frac{z^n w^{n-k}}{k!(n-k)!} \\
    &= \sum_{n=0}^{\infty} \frac{1}{n!} 
    \sum_{k=0}^{n} \mybinom{n}{k} z^n w^{n-k} 
    = \sum_{n=0}^{\infty} \frac{(z + w)^n}{n!},
\end{align*}

which gives us the important addition formula
\begin{equation}
    \label{eq:8.26}
    E(z + w) = E(z)E(w)
    \quad 
    (z, w \text{ complex}).
\end{equation}

One consequence is that
\begin{equation}
    \label{eq:8.27}
    E(z)E(-z) = E(z - z) = E(0) = 1
    \quad 
    (z \text{ complex}).
\end{equation}

% todo add words pp179(188)

\begin{equation}
    \label{eq:8.28}
    \lim_{h \to 0} \frac{E(z+h) - E(z)}{h} = 
    E(z) \lim_{h \to 0} \frac{E(h) - 1}{h} = 
    E(z);
\end{equation}

\begin{equation}
    \label{eq:8.29}
    E(z_1 + \cdots + z_n) = E(z_1) \cdots E(z_n).
\end{equation}

\begin{equation}
    \label{eq:8.30}
    E(n) = e^n
    \quad (n = 1,2,3,\dots).
\end{equation}

\begin{equation}
    \label{eq:8.31}
    \left[ E(p) \right]^m = E(mp) = E(n) = e^n,
\end{equation}

\begin{equation}
    \label{eq:8.32}
    E(p) = e^p
    \quad (p>0, p \text{ rational}).
\end{equation}

\begin{equation}
    \label{eq:8.33}
    x^y = \sup x^p
\end{equation}

\begin{equation}
    \label{eq:8.34}
    e^x = \sup e^p
    \quad (p<x, p \text{ rational}).
\end{equation}

\begin{equation}
    \label{eq:8.35}
    E(x) = e^x
\end{equation}
\mybox{推导 $E(x)$ 是自然常数指数函数}
for all real $x$. Equation (\ref{eq:8.35}) explains why $E$ is called the exponential function.

The notation $\exp(x)$ is often used in place of $e^x$, 
expecially when $x$ is a complicated expression.
Actually one may very well use (\ref{eq:8.35}) instead of (\ref{eq:8.34}) as the definition of $e^x$;
(\ref{eq:8.35}) is a much more convenient starting point for the investigation of the properties of $e^x$. 
We shall see presently that (\ref{eq:8.33}) may also be replaced by a
more convenient definition 
% [see (\ref{eq:8.43})].
[see (8.43)].

We now revert to the customary notation, $e^x$, in place of $E(x)$, 
and summarize what we have proved so far.

\begin{thm}
    \label{thm:8.6}
    Let $e^x$ be defined on $\R^1$ by (\ref{eq:8.35}) and (\ref{eq:8.25}). Then
    \begin{enumerate}[(a)]
        \item $e^x$ is continuous and differentiable for all $x$,
        \item $(e^x) = e^x$;
        \item $e^x$ is a strictly increasing function of $x$, and $e^x > 0$;
        \item $e^{x+y}$ = $e^x e^y$;
        \item $e^x \rightarrow +\infty$ as $x \rightarrow +\infty$, $e^x \rightarrow 0$ as $x \rightarrow 0$;
        \item $\lim_{x \to +\infty}  x^n e^{-x} = 0$, for every $n$.
    \end{enumerate}
\end{thm}

% todo add proof

\begin{equation*}
    e^x>\frac{x^{n+1}}{(n+1)!}
\end{equation*}

\begin{equation*}
    x^n e^{-x} < \frac{(n+1)!}{x},
\end{equation*}


Since $E$ is strictly increasing and differentiable on $\R^1$, 
it has an inverse function $L$ which is also strictly increasing and differentiable and whose domain is $E(\R^1)$, 
that is, the set of all positive numbers. $L$ is defined by
\begin{equation}
    \label{eq:8.36}
    E(L(y))=y \quad (y>0),
\end{equation}
or, equivalently, by
\begin{equation}
    \label{eq:8.37}
    E(L(x))=x \quad (x\text{ real}).
\end{equation}
Differentiating (\ref{eq:8.37}), we get (compare Theorem \ref{thm:5.5})
\begin{equation*}
    L'(E(x)) \cdot E(x) = 1.
\end{equation*}
Writing $y = E(x)$, this gives us
\begin{equation}
    \label{eq:8.38}
    L'(y) = \frac{1}{y} \quad (y>0).
\end{equation}
Taking $x = 0$ in (\ref{eq:8.37}), we see that $L(1) = 0$. 
Hence (\ref{eq:8.38}) implies
\begin{equation}
    \label{eq:8.39}
    L(y) = \int_{1}^{y} \frac{\d x}{x}.
\end{equation}
Quite frequently, (\ref{eq:8.39}) is taken as the starting-point of the theory of the logarithm and the exponential function. 
Writing $u = E(x), v = E(y)$, (\ref{eq:8.26}) gives
\begin{equation*}
    L(uv)=L(E(x)\cdot E(y)) = L(E(x+y)) = x+y,
\end{equation*}
so that
\begin{equation}
    \label{eq:8.40}
    L(uv)=L(u)+L(v) \quad (u>0,v>0).
\end{equation}

This shows that $L$ has the familiar property which makes logarithms useful tools for computation. 
The customary notation for $L(x)$ is of course $\log x$.

As to the behavior of $\log x$ as $x \rightarrow + \infty$ and as $x \rightarrow 0$, Theorem \ref{thm:8.6}(e) shows that
\begin{align*}
    \log x \rightarrow + \infty &\text{ as} x \rightarrow + \infty \\
    \log x \rightarrow - \infty &\text{ as} x \rightarrow 0.
\end{align*}

It is easily seen that
\begin{equation}
    \label{eq:8.41}
    x^n = E(nL(x))
\end{equation}
if $x > 0$ and $n$ is an integer. 
Similarly, if $m$ is a positive integer, we have
\begin{equation}
    \label{eq:8.42}
    x^{1/m} = E(\frac{1}{m}L(x)),
\end{equation}

% todo pp 190
\begin{equation}
    \label{eq:8.43}
    x^{\alpha} = E(\alpha L(x)) = e^{\alpha \log x}
\end{equation}

\begin{equation}
    \label{eq:8.44}
    (x^{\alpha})' = E(\alpha L(x))\cdot \frac{\alpha}{x} = \alpha x^{\alpha-1}.
\end{equation}


\begin{equation}
    \lim_{x \to +\infty} x^{-\alpha} \log x = 0
\end{equation}


\begin{align*}
    x^{-\alpha} \log x 
    &= x^{-\alpha} \int_{1}^{x} t^{-1} \d t
    <  x^{-\alpha} \int_{1}^{x} t^{\varepsilon-1} \d t \\
    &= x^{-\alpha} \frac{x^{\varepsilon}-1}{\varepsilon}
    <   \frac{x^{\varepsilon-\alpha}}{\varepsilon} ,
\end{align*}