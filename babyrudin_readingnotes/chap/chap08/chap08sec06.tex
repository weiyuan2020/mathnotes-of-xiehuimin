% chap08sec06
\section{The Gamma function}

This function is closely related to factorials and crops up in many unexpected places in analysis.
Its origin, history, and development are very well described in an interesting article
by P. J. Davis (\emph{Amer. Math. Monthly}, vol. 66, 1959, pp. 849-869).
Artin's book cite{ARTIN1964}(cited in the Bibliography) is another good elementary introduction.

Our presentation will be very condensed, with only a few comments after each theorem.
This section may thus be regarded as a large exercise,
and as an opportunity to apply some of the material that has been presented so far.


\begin{mydef}
    \label{mydef:8.17}
    For $0 < x < \infty$,
    \begin{equation}
        \label{eq:8.93}
        \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} \d t.
    \end{equation}
    The integral converges for these $x$.
    (When $x < 1$, both $0$ and $\infty$ have to be looked at.)
\end{mydef}


\begin{thm}
    \label{thm:8.18}
    \begin{asparaenum}[(a)]
        \item The functional equation
        \begin{equation*}
            \Gamma(x+1) = x\Gamma(x)
        \end{equation*}
        holds if $0 < x < \infty$.
        \item $\Gamma(n+1)=n!$ for $n=1,2,3,\dots$.
        \item $\log \Gamma$ is convex on $(0,\infty)$.
    \end{asparaenum}
\end{thm}


\begin{thm}
    \label{thm:8.19}
    If $f$ is a positive function on $(0, \infty)$ such that
    \begin{enumerate}[(a)]
        \item $f(x+1)=xf(x)$,
        \item $f(1)=1$,
        \item $\log f$ is convex,
    \end{enumerate}
    then $f(x) = \Gamma(x)$.
\end{thm}

\begin{proof}
    % todo
    \begin{equation}
        \label{eq:8.94}
        \phi(x+1) = \phi(x) + \log x
        \quad
        (0 < x < \infty),
    \end{equation}

    \begin{equation}
        \label{eq:8.95}
        \Gamma(x) =
        \lim_{n \to \infty} \frac{n!n^x}{x(x+1)\cdots(x+n)}
    \end{equation}
    at least when $0 < x < 1$;
    from this one can deduce that (\ref{eq:8.95}) holds for all $x > 0$,
    since $\Gamma(x+1)=x\Gamma(x)$.
\end{proof}

\begin{thm}
    \label{thm:8.20}
    If $x>0$ and $y>0$, then
    \begin{equation}
        \label{eq:8.96}
        \int_{0}^{1} t^{x-1}(1-t)^{y-1} \d t =
        \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}.
    \end{equation}
    This integral is the so-called \myKeywordblue{beta function} $B(x, y)$.
\end{thm}


\begin{proof}
    \begin{equation}
        \label{eq:8.97}
        B(x+1,y) = \frac{x}{x+y}B(x,y) .
    \end{equation}
\end{proof}


\begin{thm}
    \label{thm:8.21}
    \myKeywordblue{Some consequences}
    The substitution $t = \sin^2 \theta$ turns (\ref{eq:8.96}) into
    \begin{equation}
        \label{eq:8.98}
        2 \int_{0}^{\pi/2}
        (\sin \theta)^{2x-1}
        (\cos \theta)^{2y-1}
        \d \theta =
        \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}.
    \end{equation}
    The special case $x=y=\frac{1}{2}$ gives
    \begin{equation}
        \label{eq:8.99}
        \Gamma\left( \frac{1}{2} \right) = \sqrt{\pi} .
    \end{equation}

    The substitution $t=s^2$ turns (\ref{eq:8.93})
    \begin{equation}
        \label{eq:8.100}
        \Gamma(x) = 2 \int_{0}^{\infty} s^{2x-1} e^{-s^2} \d s
        \quad
        (0 < x < \infty)
    \end{equation}

    The special case $x=\frac{1}{2}$ gives
    \begin{equation}
        \label{eq:8.101}
        \int_{-\infty}^{\infty} e^{-s^2} \d s = \sqrt{\pi} .
    \end{equation}

    By (\ref{eq:8.99}), the identity
    \begin{equation}
        \label{eq:8.102}
        \Gamma(x) = \frac{2^{x-1}}{\sqrt{\pi}}
        \Gamma \left( \frac{x}{2} \right)
        \Gamma \left( \frac{x+1}{2} \right)
    \end{equation}
    follows directly from Theorem \ref{thm:8.19}.
\end{thm}

\begin{thm}
    \label{thm:8.22}
    \myKeywordblue{Stirling's formula}
    This provides a simple approximate expression for
    $\Gamma(x + 1)$ when $x$ is large (hence for $n!$ when $n$ is large).
    The formula is
    \begin{equation}
        \label{eq:8.103}
        \lim_{x \to \infty} \frac{\Gamma(x+1)}{(x/e)^{x}\sqrt{2\pi x}} = 1 .
    \end{equation}
    Here is a proof.
    Put $t=x(1+u)$ in (\ref{eq:8.93}).
    This gives
    \begin{equation}
        \label{eq:8.104}
        \Gamma(x+1) = x^{x+1} e^{-x}
        \int_{-1}^{\infty}
        \left[ (1+u)e^{-u} \right]^{x} \d u .
    \end{equation}
    Determine $h(u)$ so that $h(0)=1$ and
    \begin{equation}
        \label{eq:8.105}
        (1+u)e^{-u}=\exp \left[ -\frac{u^2}{2}h(u) \right]
    \end{equation}
    if $-1<u<\infty$, $u \neq 0$.
    Then
    \begin{equation}
        \label{eq:8.106}
        h(u) = \frac{2}{u^2} \left[ u - \log (1+u) \right].
    \end{equation}
    It follows that $h$ is continuous,
    and that $h(u)$ decreases monotonically from $\infty$
    to $0$ as $u$ increases from $-1$ to $\infty$.

    The substitution $u=s\sqrt{2/x}$ turns (\ref{eq:8.104}) into
    \begin{equation}
        \label{eq:8.107}
        \Gamma(x+1) = x^x e^{-x} \sqrt{2x}
        \int_{-\infty}^{\infty} \psi_x(s) \d s
    \end{equation}
    where
    \begin{equation*}
        \psi_x(s) = \left\{
        \begin{array}{ll}
            \exp \left[ -s^2 h (s\sqrt{2/x}) \right] & (-\sqrt{x/2}<s<\infty), \\
            0                                        & (s\leq -\sqrt{x/2}).    \\
        \end{array}
        \right.
    \end{equation*}
    Note the following facts about $\psi_x(s)$:
    \begin{enumerate}[(a)]
        \item For every $s$, $\psi_x(s)\rightarrow e^{-s^2}$ as $x \rightarrow \infty$.
        \item The convergence in (a) is uniform on $[-A,A]$, for every $A<\infty$.
        \item When $s<0$, then $0<\psi_x(s)<e^{-s^2}$.
        \item When $s>0$ and $x>1$, then $0<\psi_x(s)<\psi_1(s)$.
        \item $\int_{0}^{\infty}\psi_1(s)\d s<\infty$.
    \end{enumerate}
\end{thm}

The convergence theorem stated in Exercise \ref{ex:7.12} of can therefore be applied to the integral (\ref{eq:8.107}),
and shows that this integral converges to $\sqrt{\pi}$ as $x \rightarrow \infty$, by (\ref{eq:8.101}).
This proves (\ref{eq:8.103}).

A more detailed version of this proof may be found in R. C. Buck's\cite{BUCK1962} ``Advanced Calculus,''\cite{BUCK1965AdvancedCalculus} pp. 216-218.
For two other, entirely different, proofs,
see W. Feller's article in \emph{Amer. Math. Monthly}, vol. 74, 1967, pp. 1223-1225
(with a correction in vol. 75, 1968, p. 518) and pp. 20-24 of Artin's book\cite{ARTIN1964}.

Exercise \ref{ex:8.20} gives a simpler proof of a less precise result.